{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Labels ------\n",
      "{'dep_curr_src_r0': 0, 'resistor_r1': 1, 'battery_r3': 2, 'gnd_1': 3, 'dep_curr_src_r1': 4, 'battery_r2': 5, 'resistor_r0': 6, 'dc_volt_src_1_r1': 7, 'dep_volt_r3': 8, 'curr_src_r0': 9, 'dc_volt_src_1_r0': 10, 'curr_src_r1': 11, 'dep_volt_r2': 12, 'inductor_r1': 13, 'dc_volt_src_2_r2': 14, 'diode_r0': 15, 'inductor_r0': 16, 'diode_r1': 17, 'dc_volt_src_2_r3': 18, 'dep_curr_src_r3': 19, 'cap_r1': 20, 'battery_r0': 21, 'cap_r0': 22, 'dep_curr_src_r2': 23, 'battery_r1': 24, 'dep_volt_r0': 25, 'curr_src_r3': 26, 'ac_src_r0': 27, 'dc_volt_src_1_r2': 28, 'curr_src_r2': 29, 'dep_volt_r1': 30, 'dc_volt_src_1_r3': 31, 'ac_src_r1': 32, 'dc_volt_src_2_r1': 33, 'diode_r3': 34, 'diode_r2': 35, 'dc_volt_src_2_r0': 36}\n"
     ]
    }
   ],
   "source": [
    "# generate labels set\n",
    "data_path = os.path.join(os.getcwd(), 'dataset_final/')\n",
    "label_list = [l.lower().strip() for l in os.listdir(data_path) if not l.startswith('.')]\n",
    "labels = {ele:i for i, ele in enumerate(label_list)}\n",
    "print('------ Labels ------', labels, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.00683), std=(0.2440)),\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.Lambda(lambda x: x[0,:,:].T),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(data_path, transform=transform)\n",
    "train_data, val_data = random_split(dataset, [int(len(dataset)*0.8), len(dataset)-int(len(dataset)*0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ac_src_r0',\n",
       " 'ac_src_r1',\n",
       " 'battery_r0',\n",
       " 'battery_r1',\n",
       " 'battery_r2',\n",
       " 'battery_r3',\n",
       " 'cap_r0',\n",
       " 'cap_r1',\n",
       " 'curr_src_r0',\n",
       " 'curr_src_r1',\n",
       " 'curr_src_r2',\n",
       " 'curr_src_r3',\n",
       " 'dc_volt_src_1_r0',\n",
       " 'dc_volt_src_1_r1',\n",
       " 'dc_volt_src_1_r2',\n",
       " 'dc_volt_src_1_r3',\n",
       " 'dc_volt_src_2_r0',\n",
       " 'dc_volt_src_2_r1',\n",
       " 'dc_volt_src_2_r2',\n",
       " 'dc_volt_src_2_r3',\n",
       " 'dep_curr_src_r0',\n",
       " 'dep_curr_src_r1',\n",
       " 'dep_curr_src_r2',\n",
       " 'dep_curr_src_r3',\n",
       " 'dep_volt_r0',\n",
       " 'dep_volt_r1',\n",
       " 'dep_volt_r2',\n",
       " 'dep_volt_r3',\n",
       " 'diode_r0',\n",
       " 'diode_r1',\n",
       " 'diode_r2',\n",
       " 'diode_r3',\n",
       " 'gnd_1',\n",
       " 'inductor_r0',\n",
       " 'inductor_r1',\n",
       " 'resistor_r0',\n",
       " 'resistor_r1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ac_src_r0': 0,\n",
       " 'ac_src_r1': 1,\n",
       " 'battery_r0': 2,\n",
       " 'battery_r1': 3,\n",
       " 'battery_r2': 4,\n",
       " 'battery_r3': 5,\n",
       " 'cap_r0': 6,\n",
       " 'cap_r1': 7,\n",
       " 'curr_src_r0': 8,\n",
       " 'curr_src_r1': 9,\n",
       " 'curr_src_r2': 10,\n",
       " 'curr_src_r3': 11,\n",
       " 'dc_volt_src_1_r0': 12,\n",
       " 'dc_volt_src_1_r1': 13,\n",
       " 'dc_volt_src_1_r2': 14,\n",
       " 'dc_volt_src_1_r3': 15,\n",
       " 'dc_volt_src_2_r0': 16,\n",
       " 'dc_volt_src_2_r1': 17,\n",
       " 'dc_volt_src_2_r2': 18,\n",
       " 'dc_volt_src_2_r3': 19,\n",
       " 'dep_curr_src_r0': 20,\n",
       " 'dep_curr_src_r1': 21,\n",
       " 'dep_curr_src_r2': 22,\n",
       " 'dep_curr_src_r3': 23,\n",
       " 'dep_volt_r0': 24,\n",
       " 'dep_volt_r1': 25,\n",
       " 'dep_volt_r2': 26,\n",
       " 'dep_volt_r3': 27,\n",
       " 'diode_r0': 28,\n",
       " 'diode_r1': 29,\n",
       " 'diode_r2': 30,\n",
       " 'diode_r3': 31,\n",
       " 'gnd_1': 32,\n",
       " 'inductor_r0': 33,\n",
       " 'inductor_r1': 34,\n",
       " 'resistor_r0': 35,\n",
       " 'resistor_r1': 36}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate mean and std of dataset\n",
    "\n",
    "# mean = 0.\n",
    "# std = 0.\n",
    "\n",
    "# for images, _ in dataset:\n",
    "#     mean += images.view(1, -1).mean(dim=1)\n",
    "#     std += images.view(1, -1).std(dim=1)\n",
    "\n",
    "# mean /= len(dataset)\n",
    "# std /= len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model class\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.con1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.acv1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.con2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.acv2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.con3 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.acv3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.con4 = nn.Conv2d(32, 16, 3, padding=1)\n",
    "        self.acv4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.lin1 = nn.Linear(16*4*4, 1024)\n",
    "        self.act5 = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(1024, 37)\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.pool1(self.acv1(self.con1(img)))\n",
    "        out = self.pool2(self.acv2(self.con2(out)))\n",
    "        out = self.pool3(self.acv3(self.con3(out)))\n",
    "        out = self.pool4(self.acv4(self.con4(out)))\n",
    "        out = out.view(-1, 16*4*4)\n",
    "        out = self.act5(self.lin1(out))\n",
    "        out = self.lin2(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-2)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rushirajgadhvi/miniforge3/envs/torch/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs, labels)\n\u001b[1;32m      7\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m      9\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     11\u001b[0m loss_train \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs + 1):\n",
    "    loss_train = 0.0\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.unsqueeze(1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train += loss.item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('{} Epoch {}, Training loss {}'.format(datetime.datetime.now(), epoch,loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the Train images: 99.98289721224559 %\n",
      "Accuracy of the network on the Validation images: 90.73187414500684 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for name, loader in [('Train', train_loader), ('Validation', val_loader)]:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            outputs = model(imgs.unsqueeze(1))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            y_pred.extend(predicted)\n",
    "            y_true.extend(labels)\n",
    "\n",
    "    print('Accuracy of the network on the {} images: {} %'.format(name, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.save(model, 'model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
