{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Labels ------\n",
      "{'dep_curr_src_r0': 0, 'resistor_r1': 1, 'battery_r3': 2, 'gnd_1': 3, 'dep_curr_src_r1': 4, 'battery_r2': 5, 'resistor_r0': 6, 'dc_volt_src_1_r1': 7, 'dep_volt_r3': 8, 'curr_src_r0': 9, 'dc_volt_src_1_r0': 10, 'curr_src_r1': 11, 'dep_volt_r2': 12, 'inductor_r1': 13, 'dc_volt_src_2_r2': 14, 'diode_r0': 15, 'inductor_r0': 16, 'diode_r1': 17, 'dc_volt_src_2_r3': 18, 'dep_curr_src_r3': 19, 'cap_r1': 20, 'battery_r0': 21, 'cap_r0': 22, 'dep_curr_src_r2': 23, 'battery_r1': 24, 'dep_volt_r0': 25, 'curr_src_r3': 26, 'ac_src_r0': 27, 'dc_volt_src_1_r2': 28, 'curr_src_r2': 29, 'dep_volt_r1': 30, 'dc_volt_src_1_r3': 31, 'ac_src_r1': 32, 'dc_volt_src_2_r1': 33, 'diode_r3': 34, 'diode_r2': 35, 'dc_volt_src_2_r0': 36}\n"
     ]
    }
   ],
   "source": [
    "# generate labels set\n",
    "data_path = os.path.join(os.getcwd(), 'dataset_final/')\n",
    "label_list = [l.lower().strip() for l in os.listdir(data_path) if not l.startswith('.')]\n",
    "labels = {ele:i for i, ele in enumerate(label_list)}\n",
    "print('------ Labels ------', labels, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.00683), std=(0.2440)),\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.Lambda(lambda x: x[0,:,:].T),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(data_path, transform=transform)\n",
    "train_data, val_data = random_split(dataset, [int(len(dataset)*0.8), len(dataset)-int(len(dataset)*0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ac_src_r0',\n",
       " 'ac_src_r1',\n",
       " 'battery_r0',\n",
       " 'battery_r1',\n",
       " 'battery_r2',\n",
       " 'battery_r3',\n",
       " 'cap_r0',\n",
       " 'cap_r1',\n",
       " 'curr_src_r0',\n",
       " 'curr_src_r1',\n",
       " 'curr_src_r2',\n",
       " 'curr_src_r3',\n",
       " 'dc_volt_src_1_r0',\n",
       " 'dc_volt_src_1_r1',\n",
       " 'dc_volt_src_1_r2',\n",
       " 'dc_volt_src_1_r3',\n",
       " 'dc_volt_src_2_r0',\n",
       " 'dc_volt_src_2_r1',\n",
       " 'dc_volt_src_2_r2',\n",
       " 'dc_volt_src_2_r3',\n",
       " 'dep_curr_src_r0',\n",
       " 'dep_curr_src_r1',\n",
       " 'dep_curr_src_r2',\n",
       " 'dep_curr_src_r3',\n",
       " 'dep_volt_r0',\n",
       " 'dep_volt_r1',\n",
       " 'dep_volt_r2',\n",
       " 'dep_volt_r3',\n",
       " 'diode_r0',\n",
       " 'diode_r1',\n",
       " 'diode_r2',\n",
       " 'diode_r3',\n",
       " 'gnd_1',\n",
       " 'inductor_r0',\n",
       " 'inductor_r1',\n",
       " 'resistor_r0',\n",
       " 'resistor_r1']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate mean and std of dataset\n",
    "\n",
    "# mean = 0.\n",
    "# std = 0.\n",
    "\n",
    "# for images, _ in dataset:\n",
    "#     mean += images.view(1, -1).mean(dim=1)\n",
    "#     std += images.view(1, -1).std(dim=1)\n",
    "\n",
    "# mean /= len(dataset)\n",
    "# std /= len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model class\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.con1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.acv1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.con2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.acv2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.con3 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.acv3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.con4 = nn.Conv2d(32, 16, 3, padding=1)\n",
    "        self.acv4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.lin1 = nn.Linear(16*4*4, 1024)\n",
    "        self.act5 = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(1024, 37)\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.pool1(self.acv1(self.con1(img)))\n",
    "        out = self.pool2(self.acv2(self.con2(out)))\n",
    "        out = self.pool3(self.acv3(self.con3(out)))\n",
    "        out = self.pool4(self.acv4(self.con4(out)))\n",
    "        out = out.view(-1, 16*4*4)\n",
    "        out = self.act5(self.lin1(out))\n",
    "        out = self.lin2(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-2)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-07 11:51:51.057389 Epoch 0, Training loss 2.616977506647996\n",
      "2023-05-07 12:00:30.942040 Epoch 10, Training loss 0.1082963974162926\n",
      "2023-05-07 12:08:49.579550 Epoch 20, Training loss 0.0035748853739772783\n",
      "2023-05-07 12:17:45.574801 Epoch 30, Training loss 0.0003017254136852774\n",
      "2023-05-07 12:26:17.897856 Epoch 40, Training loss 0.00020504278850947856\n",
      "2023-05-07 12:35:08.104104 Epoch 50, Training loss 0.0001751331840067883\n",
      "2023-05-07 12:43:59.113871 Epoch 60, Training loss 0.00016614307228631102\n",
      "2023-05-07 12:52:39.528572 Epoch 70, Training loss 0.00016014142241617955\n",
      "2023-05-07 13:01:53.815687 Epoch 80, Training loss 0.00015145274121466888\n",
      "2023-05-07 13:10:33.198696 Epoch 90, Training loss 0.00014847343132482396\n",
      "2023-05-07 13:57:45.946182 Epoch 100, Training loss 0.0001456584627678079\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs + 1):\n",
    "    loss_train = 0.0\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.unsqueeze(1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train += loss.item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('{} Epoch {}, Training loss {}'.format(datetime.datetime.now(), epoch,loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the Train images: 99.9914486061228 %\n",
      "Accuracy of the network on the Validation images: 90.35567715458276 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for name, loader in [('Train', train_loader), ('Validation', val_loader)]:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            outputs = model(imgs.unsqueeze(1))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            y_pred.extend(predicted)\n",
    "            y_true.extend(labels)\n",
    "\n",
    "    print('Accuracy of the network on the {} images: {} %'.format(name, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.save(model, 'model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
